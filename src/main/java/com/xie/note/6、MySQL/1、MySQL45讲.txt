原则1：加锁的基本单位是 next-key lock。
原则2：查找过程中访问到的对象才会加锁。

优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

01 | 基础架构：一条SQL查询语句是如何执行的？
Server层
    Server 层包括连接器、查询缓存、分析器、优化器、执行器
    涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等
    连接器：
        连接器负责跟客户端建立连接、获取权限、维持和管理连接
        mysql -h$ip -P$port -u$user -p
        连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，show processlist，Sleep
        wait_timeout控制自动断开时间
        使用长链接后，内存长得特别快，放入如下：
        1、定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连
        2、5.7之后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。
    查询缓存：
        MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中
        我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利
        查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空
    分析器：
        分析器先会做“词法分析”。做完了这些识别以后，就要做“语法分析”。
    优化器：
        优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序
    执行器：
        要先判断一下你对这个表 T 有没有执行查询的权限
        慢查询日志中看到一个 rows_examined，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的
小结：
问题：
    如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？
    是分析器

2、一条SQL更新语句是如何执行的？
    更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）
    1、redo log
        MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘
        InnoDB 引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。
        redo log，从头开始写，写到末尾就又回到开头循环写。write pos 是当前记录的位置，checkpoint 是当前要擦除的位置。
        redo log保证了，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。
    2、binlog
        Server 层也有自己的日志，称为 binlog（归档日志）
    3、异同
        （1）redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
        （2）redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
        （3）redo log 是循环写的，空间固定；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
    4、执行器和存储引擎在更新时动作
        （1）执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
        （2）执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
        （3）引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
        （4）执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
        （5）执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。
    5、两阶段提交
        恢复到指定的某一秒
        （1）首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库
        （2）然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。
        为什么需要两阶段提交
        （1）先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。
        （2）先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。
        如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
        redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。
    6、小结：
        redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
        sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。
        两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案
    7、问题
        前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？
        答案：一周一备最坏情况就要应用一周的 binlog 了。系统的对应指标就是（恢复目标时间）。

03 | 事务隔离：为什么你改了我还看不见？
    事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。

    1、隔离性与隔离级别
        ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）
        多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。
        SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）
        读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
        读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
        可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
        串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

        数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。
        在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
        在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念。
        “串行化”隔离级别下直接用加锁的方式来避免并行访问。
        配置的方式是，将启动参数 transaction_isolation 的值设置成 REPEATABLE-READ
    2、事务隔离的实现
        实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。
        同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）
        对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。
        当系统里没有比这个回滚日志更早的 read-view，系统才会删除相应的回滚日志
        长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，
        所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
        回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小
        除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库
    3、事务的启动方式
        （1）显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
        （2）set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
        建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务
        查询长事务(超过60s)：
            select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
    4、小结
    5、问题：
        你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？
        应用开发端：
        （1）autocommit,通过临时开启general_log，确认autocommit的值
        （2）确认是否有不必要的只读事务
        （3）通过SET MAX_EXECUTION_TIME，设置最长执行时间
        数据库端
        （1）监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
        （2）Percona 的 pt-kill 这个工具不错，推荐使用；
        （3）在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
        （4）如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。
04 | 深入浅出索引（上）
    索引的出现其实就是为了提高数据查询的效率
    1、索引的常见模型
        （1）哈希表
            哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。
            哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。
            增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的
            哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。
        （2）有序数组
            有序数组在等值查询和范围查询场景中的性能就都非常优秀，用二分法就可以快速得到，这个时间复杂度是 O(log(N))
            如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。
            有序数组索引只适用于静态存储引擎
        （3）二叉搜索树
            二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。
            当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。
            二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。
            为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。
            N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。
    2、InnoDB 的索引模型
        表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的
        根据叶子节点的内容，索引类型分为主键索引和非主键索引。
            （1）主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。
            （2）非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。
        基于主键索引和普通索引的查询有什么区别？
            （1）主键查询方式，则只需要搜索 ID 这棵 B+ 树；
            （2）普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表
        基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。
    3、索引维护
        维护有序性：B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护
        页分裂：
            数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。
            页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%
            当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。
            自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。
            自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
            业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。
            主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。
            什么场景适合用业务字段直接做主键：
            （1）只有一个索引；
            （2）该索引必须是唯一索引。
              优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。
    4、小结：
        B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数
        InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小
    5、问题
        重建索引语句是否合理：
            1、alter table T drop index k;alter table T add index(k);
            2、alter table T drop primary key;alter table T add primary key(id);
        答案：
            1、重建索引 k 的做法是合理的，可以达到省空间的目的。
            2、重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。

05 | 深入浅出索引（下）
    1、覆盖索引
        索引覆盖了我们的擦汗寻需求，我们称为覆盖索引
        由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段
        可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。
        索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作
    2、最左前缀原则
        B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录
        索引项是按照索引定义里面出现的字段顺序排序的
        不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。
        在建立联合索引的时候，如何安排索引内的字段顺序？
        （1）第一原则是，索引复用能力，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的
        （2）第二个原则就是空间
    3、索引下推
        （1）MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。
        （2）MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
    4、小结
        在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。

06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？
    MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类
    1、全局锁
        全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。
        全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。
        通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。
        （1）如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
        （2）如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

        备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的
        有一个方法能够拿到一致性视图的，对吧？是的，就是在可重复读隔离级别下开启一个事务。

        mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。
        为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了.
        single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。

        为什么不用set global readonly=true，主要原因：
        （1）在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。
        （2）FTWRL遇到异常会断开，readonly则是会一直保持这个状态，风险较高

        业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。

    2、表级锁
        一种是表锁，一种是元数据锁（meta data lock，MDL)。
        （1）普通表锁
        表锁的语法是 lock tables … read/write，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。
        lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
        没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大
        （2）MDL表锁
            当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
            MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。
            （1）读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
            （2）读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。
            因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
            所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。
            事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

            如何安全地给小表加字段？
            （1）我们要解决长事务，事务不提交，就会一直占着MDL锁
                在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。
            （2）如果是热点表怎么办?
                在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。
                ALTER TABLE tbl_name NOWAIT add column ...
                ALTER TABLE tbl_name WAIT N add column ...
    3、小结
        全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。
        表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：
        （1）要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；
        （2）要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。
        MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。
    4、问题：
    如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。
    如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；
    如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。
    从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。

07 | 行锁功过：怎么减少行锁对性能的影响？
    MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。
    不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。
    InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

    行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。
    1、两阶段锁
        在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
        如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
    2、死锁和死锁检测
        当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
        出现死锁之后，有两种策略：
        （1）直接进入等待，直到超时，通过innodb_lock_wait_timeout设置
        （2）发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on
        对于第1种，第一个被锁住的线程要过 50s 才会超时退出，这个等待时间往往是无法接受的；如果设置超时时间设置太短的话，会出现很多误伤；
        所以，我们常采用第2种，即：主动死锁检测。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。

        每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。
        问题的症结在于，死锁检测要耗费大量的 CPU 资源。
        两种策略：
        （1）如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉
        （2）控制并发度。如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题
            对于相同行的更新，在进入引擎之前排队。
            将一行改成逻辑上的多行来减少锁冲突。
    3、小结
        如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。
        减少死锁的主要方向，就是控制访问相同资源的并发事务量

08 | 事务到底是隔离的还是不隔离的？
    如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view。之后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动时看到的一样。
    一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。
    begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。
    创建一致性视图的时机
    （1）begin/start transaction
        执行第一个快照读语句时创建
    （2）start transaction with consistent snapshot
        执行该语句时创建
     mysql试图的两个概念：
     （1）view:它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样
     （2）InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。
        它没有什么物理结构，作用是事务执行期间用来定义“我能看到什么数据”。
    1、“快照”在 MVCC 里是怎么工作的？
        在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。
        InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。
        每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。
        数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。

        //下面没看懂
        InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。
        数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。
        这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。
        InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。

        对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：
        如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
        如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
        如果落在黄色部分，那就包括两种情况
            a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
            b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

        InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。

        一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
            版本未提交，不可见；
            版本已提交，但是是在视图创建后提交的，不可见；
            版本已提交，而且是在视图创建前提交的，可见。
    
    2、更新逻辑
        更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。
        在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。
        在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。
        除了 update 语句外，select 语句如果加锁，也是当前读。
            mysql> select k from t where id=1 lock in share mode;
            mysql> select k from t where id=1 for update;

        可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

        读提交的逻辑和可重复读的逻辑类似，它们最主要的区别：
        1、在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
        2、在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

        “start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 start transaction。

    3、小结：
        InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。
        普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。
            对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
            对于读提交，查询只承认在语句启动前就已经提交完成的数据；
        当前读，总是读取已经提交完成的最新版本。

        为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。

09 | 普通索引和唯一索引，应该怎么选择？
    由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。
    1、查询过程
        select id from T where k=5。
        先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。
        （1）对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
        （2）对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
        这个不同带来的性能差距会有多少呢？答案是，微乎其微。

        InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。
        因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。
        对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。

    2、更新过程
        change buffer。
            当需要更新一个数据页时，如果数据页在内存中就直接更新。
            如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。
            在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。
            虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

            将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。
            除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

            如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。
            而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。

        什么条件下可以使用 change buffer 呢？
            唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。
            唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。

            change buffer 用的是 buffer pool 里的内存，因此不能无限增大。
            change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。
            这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

        如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。
            1、这个记录要更新的目标页在内存中
                （1）对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
                （2）对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。
                普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。
            2、这个记录要更新的目标页不在内存中
                （1）对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
                （2）对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。
                将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。
        change buffer 的使用场景
            change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。
            merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

            对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。

            假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

    3、索引选择和实践
        这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引
        如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。
        在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。

    4、change buffer 和 redo log(感觉作者写的有问题：插入存在主键，应该跟change buffer没关系)
        insert into t(id,k) values(id1,k1),(id2,k2);
        分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。
        (1)Page 1 在内存中，直接更新内存；
        (2)Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 
        (3)插入一行”这个信息将上述两个动作记入 redo log 中（图中 3 和 4）。

        select * from t where k in (k1, k2)
        （1）读 Page 1 的时候，直接从内存返回
        （2）要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。
        直到需要读 Page 2 的时候，这个数据页才会被读入内存。

        所以，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。

    5、小结
        唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。

    6、问题
        change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。
        答案：
            不会丢失，在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。

            merge 的执行流程：
            （1）从磁盘读入数据页到内存（老版本的数据页）；
            （2）从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
            （3）写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。
            到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

10 | MySQL为什么有时候会选错索引？
    1、分析sql
        set long_query_time=0;
        select * from t where a between 10000 and 20000; /*Q1*/
        select * from t force index(a) where a between 10000 and 20000;/*Q2*/
        第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；
        第二句，Q1 是 session B 原来的查询；
        第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。

    2、优化器的逻辑
        优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。
        在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。
        当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。
        （1）扫描行数是怎么判断的（没看明白，也许是因为作者没有给出选择区分度的公式）
            统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。
            而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。
            show index 方法，看到一个索引的基数。

            MySQL 是怎样得到索引的基数的呢？
                因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。
                采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。
                数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计

            两种存储索引统计的方式
                设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
                设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

            索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。
                通过explain的rows判断预计扫描行数
                可能你的第一个疑问不是为什么不准？这是因为，如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价

            既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。     
            如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。

        (2)索引选择异常和处理
            a、一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引
            b、第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。
            c、第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。
    3、小结
        索引统计信息不准确导致的问题，你可以用 analyze table 来解决。
        你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。

11 | 怎么给字符串字段加索引？
    1、合理使用前缀索引
        使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。
        建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。
        mysql> select 
                  count(distinct left(email,4)）as L4,
                  count(distinct left(email,5)）as L5,
                  count(distinct left(email,6)）as L6,
                  count(distinct left(email,7)）as L7,
                from SUser;
        使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。

    2、前缀索引对覆盖索引的影响
        使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。
    3、其他方式
        索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。
        关于身份证，前缀索引区分度太小，可以采用以下方案：
        a、第一种方式是使用倒序存储。
            mysql> select field_list from t where id_card = reverse('input_id_card_string');
        b、第二种方式是使用 hash 字段。
            mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);
            索引的长度变成了 4 个字节，比原来小了很多。
        使用倒序存储和使用 hash 字段这两种方法的异同点
            相同点：
                首先，它们的相同点是，都不支持范围查询。
            不同点：
                a、从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。
                b、在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
                c、从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

    4、小结
        （1）直接创建完整索引，这样可能比较占用空间；
        （2）创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
        （3）倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
        （4）创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

12 | 为什么我的MySQL会“抖”一下？
    1、你的 SQL 语句为什么变“慢”了
        InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），在更新内存写完 redo log 后，就返回给客户端，本次更新成功。
        把内存里的数据写入磁盘的过程，术语就是 flush。
        当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。
        不论是脏页还是干净页，都在内存中。
        其实就是在写内存和
        日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）

    2、什么情况下会刷脏页呢
        （1）redo log满了，这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。
        （2）系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
            如果刷脏页一定会写盘，就保证了每个数据页有两种状态：
            （1）一种是内存里存在，内存里就肯定是正确的结果，直接返回；
            （2）另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。

        （3）系统空闲时候
            对应的就是MySQL认为系统“空闲”的时候。即使是稍微空闲的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。

        （4）正常停服务

        第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。
        第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：
            （1）没有使用的
            （2）使用了并且是干净页
            （3）使用的是脏页
            InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。
            要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：
                如果要淘汰的是一个干净页，就直接释放出来复用；
                但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。
            所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：
                a、一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
                b、日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。

    3、InnoDB 刷脏页的控制策略
        你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。
        innodb_io_capacity，建议设置为磁盘的IOPS
         fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 

        InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。
        你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。
        其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：
        mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
        select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
        select @a/@b;

        一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。
        而 MySQL 中的一个机制，可能让你的查询会更慢：
            在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；
            而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。
        InnoDB用参数：innodb_flush_neighbors，控制刷邻居页的行为

        找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。
        SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。

    4、小结
        利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。
        内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。

    5、问题
        如果一个高配的机器，redo log 设置太小，会发生什么情况？
        每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。
        这时候系统不得不停止所有更新，去推进 checkpoint。这时，你看到的现象就是磁盘压力很小，但是数据库出现间歇性的性能下跌。

13 | 为什么表数据删掉一半，表文件大小不变？
    一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。
    1、参数 innodb_file_per_table
        a、这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
        b、这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。
        无论哪个版本都建议设置为on,一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

    2、数据删除流程
        我们要删掉某个记录，InnoDB 引擎只会把这个记录标记为删除。如果之后要再插入相同或者近似记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。
        那么如果我们删掉了一个数据页上的所有记录，会怎么样？答案是，整个数据页就可以被复用了。
        数据页的复用跟记录的复用是不同的。
            a、记录的复用，只限于符合范围条件的数据
            b、整个页从 B+ 树里面摘掉以后，可以复用到任何位置
                如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。
                如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。
        
        不止是删除数据会造成空洞，插入数据也会
            如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。

        更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。

        经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。
            而重建表，就可以达到这样的目的。

    3、重建表
        查看表的大小：SHOW TABLE STATUS LIKE 'table_name'; 
        重建表：alter table A engine=InnoDB
        花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失

        MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化，流程如下：
        （1）、建立一个临时文件，扫描表 A 主键的所有数据页；
        （2）用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
        （3）生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
        （4）临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
        （5）用临时文件替换表 A 的数据文件。
        由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。
        alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。
        Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。
        上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。

    4、Online 和 inplace
        我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。
        在图 4 中，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。

        我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：alter table t engine=innodb,ALGORITHM=inplace;
        跟 inplace 对应的就是拷贝表的方式了，用法是：alter table t engine=innodb,ALGORITHM=copy

        inplace 跟 Online 是不是就是一个意思？其实不是的，只是在重建表这个逻辑中刚好是这样而已。
        比如，如果我要给 InnoDB 表的一个字段加全文索引，写法是：alter table t add FULLTEXT(field_name);
        这个过程是 inplace 的，但会阻塞增删改操作，是非 Online 的。


        如果说这两个逻辑之间的关系是什么的话，可以概括为：
        （1）DDL 过程如果是 Online 的，就一定是 inplace 的；
        （2）反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。
    5、optimize table、analyze table 和 alter table 这三种方式重建表
        （1）alter table t engine = InnoDB（也就是 recreate）默认的就是上面图 4 的流程了；
        （2）analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；
        （3）optimize table t 等于 recreate+analyze。

    6、小结
        如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的，
        你还要通过 alter table 命令重建表，才能达到表文件变小的目的。
        Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。

14 | count(*)这么慢，我该怎么办？
    1、count(*) 的实现方式
        （1）MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；
        （2）而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。
        如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。

        为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？
        这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的

        其实innodb在这个上面是做了优化的
        InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。
        所以，普通索引树比主键索引树小很多。
        对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。
        因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

        TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。

        小结下： 
            MyISAM 表虽然 count(*) 很快，但是不支持事务；
            show table status 命令虽然返回很快，但是不准确；
            InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。
            
            如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？
            答案是，我们只能自己计数。
    
    2、用缓存系统保存计数
        （1）缓存系统可能会丢失更新
        （2）在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使 Redis 正常工作，这个计数值还是逻辑上不精确的。

    3、在数据库保存计数
        首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。
        可以利用“事务”这个特性，把不一致的问题解决掉。

    4、不同的 count 用法
        count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。
        所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。
        至于分析性能差别的时候，你可以记住这么几个原则：
        （1）server 层要什么就给什么；
        （2）InnoDB 只给必要的值；
        （3）现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。

        对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
        对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

        对于 count(字段) 来说：
            如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
            如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。
        但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。
        
        所以结论是：按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*)

    5、小结：
        计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图

15 | 答疑文章（一）：日志和索引相关问题
    1、日志相关问题
        （1）在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象
            写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库
            
            主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？
            a、如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
            b、如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。

        （2）追问 1：MySQL 怎么知道 binlog 是完整的?
            a、statement 格式的 binlog，最后会有 COMMIT；
            b、row 格式的 binlog，最后会有一个 XID event。
            MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。

        （3）追问 2：redo log 和 binlog 是怎么关联起来的?
            它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：
            a、如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
            b、如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

        （4）追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?
            这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。
            所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。

        （5）追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？
            对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。
            而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。
            两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。

        （6）追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？（没明白，不懂）
            这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。
            如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。
            但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。
            如果之后崩溃，要依赖于日志来恢复数据页。也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。
            你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。

        （7）那能不能反过来，只用 redo log，不要 binlog？
            你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。
            一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。
            一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。
        
        （8）追问 7：redo log 一般设置多大？
            几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。

        （9）正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？
            实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新”的情况。
                a、如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。
                b、在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。

        （10）redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？
            这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。
            所以，redo log buffer 就是一块内存，用来先存 redo 日志的。
            在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。
            真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。
    
    2、业务设计问题
        业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。

    3、小结
        无

16 | “order by”是怎么工作的？
    一、全字段排序
        Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。
        （1）初始化 sort_buffer，确定放入 name、city、age 这三个字段；
        （2）从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
        （3）到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
        （4）从索引 city 取下一个记录的主键 id；
        （5）重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；
        （6）对 sort_buffer 中的数据按照字段 name 做快速排序；按照排序结果取前 1000 行返回给客户端。
        
        “按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。
        sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

        确定是否使用了临时文件
            /* 打开optimizer_trace，只对本线程有效 */
            SET optimizer_trace='enabled=on'; 

            /* @a保存Innodb_rows_read的初始值 */
            select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

            /* 执行语句 */
            select city, name,age from t where city='杭州' order by name limit 1000; 

            /* 查看 OPTIMIZER_TRACE 输出 */
            SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

            /* @b保存Innodb_rows_read的当前值 */
            select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

            /* 计算Innodb_rows_read差值 */
            select @b-@a;
        这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。
        number_of_tmp_files 表示的是，排序过程中使用的临时文件数。
        MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。

        如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。
        否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。
        其他几个字段的属性意思
            （1）examined_rows=4000，表示参与排序的行数是 4000 行。
            （2）sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。
            （3）select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。
            为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。
            这是因为查询OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。

    2、rowid 排序
        如果 MySQL 认为排序的单行长度太大会怎么做呢？
        SET max_length_for_sort_data = 16;
        max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

        新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。
        （1）初始化 sort_buffer，确定放入两个字段，即 name 和 id；
        （2）从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
        （2）到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
        （4）从索引 city 取下一个记录的主键 id；
        （5）重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；
        （6）对 sort_buffer 中的数据按照字段 name 进行排序；
        （7）遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

        根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？
        现在，我们就来看看结果有什么不同。首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。
        但是 select @b-@a 这个语句的值变成 5000 了。
        因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。

        从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。sort_mode 变成了 ，表示参与排序的只有 name 和 id 这两个字段。number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。

    3、全字段排序 VS rowid 排序
        MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。
        如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。

        这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。

        MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。

    4、添加合适的索引
        alter table t add index city_user(city, name);
        （1）从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；
        （2）到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；
        （3）从索引 (city,name) 取下一个记录主键 id；
        （4）重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

        Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。

        这个语句的执行流程有没有可能进一步简化呢？
        覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。
        alter table t add index city_user_age(city, name, age);
        （1）从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；
        （2）从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；
        （3）重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束

        Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。

    5、小结
        
17 | 如何正确地显示随机消息？（没明白，需要重刷）
    1、内存临时表
        mysql> select word from words order by rand() limit 3;
        Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。
        对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。
        对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。
        这条语句的执行流程是这样的：
        （1）创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。
        （2）从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。
        （3）现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。
        （4）初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。
        （5）从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。
        （6）在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。

        通过慢查询日志（slow log）来验证
        # Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003
        SET timestamp=1541402277;
        select word from words order by rand() limit 3;
        Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了我们分析得出的结论。

        MySQL 的表是用什么方法来定位“一行数据”的。
        如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。实际上它表示的是：每个引擎用来唯一标识数据行的信息。

        实际上它表示的是：每个引擎用来唯一标识数据行的信息。
        (1)对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；
        (2)对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；
        (3)MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。
        order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。
``
    2、磁盘临时表
        tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。
        磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。
        当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。
        为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。
        set tmp_table_size=1024;
        set sort_buffer_size=32768;
        set max_length_for_sort_data=16;
        /* 打开 optimizer_trace，只对本线程有效 */
        SET optimizer_trace='enabled=on';
        /* 执行语句 */
        select word from words order by rand() limit 3;
        /* 查看 OPTIMIZER_TRACE 输出 */
        SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
        这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。

        优先队列算法，就可以精确地只得到三个最小值
        （1）对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）
        （2）取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；
        （3）重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。

        OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。

        select city,name,age from t where city='杭州' order by name limit 1000  ;
        为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。

    3、随机排序方法
        为了得到严格随机的结果，你可以用下面这个流程:
        （1）取得整个表的行数，并记为 C。
        （2）取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。
        （3）再用 limit Y,1 取得一行。

        mysql> select count(*) into @C from t;
        set @Y1 = floor(@C * rand());
        set @Y2 = floor(@C * rand());
        set @Y3 = floor(@C * rand());
        select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行
        select * from t limit @Y2，1；
        select * from t limit @Y3，1；

    4、小结
        order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要尽量避开这种写法。
        比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情

18 | 为什么这些SQL语句逻辑相同，性能却差异巨大？
    在 MySQL 中，有很多看上去逻辑相同，但性能却差异巨大的 SQL 语句。对这些语句使用不当的话，就会不经意间导致整个数据库的压力变大。
    1、案例一：条件字段函数操作
        mysql> select count(*) from tradelog where month(t_modified)=7;
        实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。
        但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。
        对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。

        需要注意的是，优化器并不是要放弃使用这个索引。
        放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。
        因此最终还是会选择索引 t_modified。

        我们使用 explain 命令，查看一下这条 SQL 语句的执行结果。
        key="t_modified"表示的是，使用了 t_modified 这个索引；
        我在测试表数据中插入了 10 万行数据，rows=100335，说明这条语句扫描了整个索引的所有值；
        Extra 字段的 Using index，表示的是使用了覆盖索引。
        由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。

        按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。
        mysql> select count(*) from tradelog where
            -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or
            -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or
            -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
        由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。

    2、案例二：隐式类型转换
        mysql> select * from tradelog where tradeid=110717;
        tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。
        字符串和数字做比较的话，是将字符串转换成数字。
        对于优化器来说，这个语句相当于
        mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;

    3、案例三：隐式字符编码转换
        字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集。
        也都是“按数据长度增加的方向”进行转换的。
        mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/
        实际上这个语句等同于下面这个写法：
        select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;
        这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。

        连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。
        两种优化办法：
        （1）、把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。
        （2）、如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了
            mysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;
            将驱动表的转为utf8
    4、小结
        对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。
        第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。
        MySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。
        每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。

    5、问题

19 | 为什么我只查一行的语句，也执行这么慢
    如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范围。
    简单语句的问题
    1、查询长时间不返回
        大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。
        （1）等MDL锁
            使用 show processlist 命令查看 Waiting for table metadata lock
            现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。
            session A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。
            谁持有 MDL 写锁，然后把它 kill 掉：
            （MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)
            通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。
        （2）等flush
            mysql> select * from information_schema.processlist where id=1;
            我查出来这个线程的状态是 Waiting for table flush
            表的flush操作：
                flush tables t with read lock;
                flush tables with read lock;
                如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。
                所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。
            通过show processlist找到线程ID，kill掉
        （3）等行锁
            通过：select * from sys.innodb_lock_waits where locked_table='`test`.`t`'
            KILL QUERY 4 或 KILL 4。

    2、查询长时间不返回
        （1）没有索引或者没有合适的索引
            set long_query_time = 0;
            select * from t where c=50000 limit 1;
            Rows_examined 显示扫描了 50000 行。坏查询不一定是慢查询，数据量大起来的话，执行时间就线性涨上去了。
        （2）当前读，读取了过多的undo log


20 | 幻读是什么，幻读有什么问题？
    1、幻读是什么
        幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行
        说明：
        （1）在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
        （2）上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。
        当前读的规则，就是要能读到所有已经提交的记录的最新值

    2、幻读的问题
        破坏了加锁的声明；其次，是数据一致性的问题。
        锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。
        即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。

    3、如果解决幻读
        产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。
        因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。
        间隙锁和行锁的不同：
            跟行锁有冲突关系的是“另外一个行锁”。
            跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作
        间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。
        间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。
        间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。

        读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。

        业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。

        mysqldump 为什么要把备份线程设置成可重复读呢？
            来确保拿到一致性视图。

    4、小结
        提到了全表扫描的加锁方式。我们发现即使给所有的行都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。
        行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循

21 | 为什么我只改一行的语句，锁这么多？
    1、原则和优化
        原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
        原则 2：查找过程中访问到的对象才会加锁。
        优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
        优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
        一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

    2、案例一：等值查询间隙锁
    3、案例二：非唯一索引等值锁
    4、案例三：主键索引范围锁
    5、案例四：非唯一索引范围锁
    6、案例五：唯一索引范围锁 bug
    7、案例六：非唯一索引上存在"等值"的例子
    8、案例七：limit 语句加锁
        在删除数据的时候尽量加 limit
    9、案例八：一个死锁的例子

    10、小结：
        可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。
        next-key lock 实际上是由间隙锁加行锁实现的。
        在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。
        也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。

        问题答案：
        由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。
        在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。
        在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。

23 | MySQL是怎么保证数据不丢的？
    只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。
    1、binlog 的写入机制
        事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。
        一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。
        系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。
        事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。

        每个线程有自己 binlog cache，但是共用同一份 binlog 文件。
        （1）图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。
        （2）图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

        write 和 fsync 的时机，是由参数 sync_binlog 控制的：
        （1）sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；
        （2）sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
        （3）sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

        在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

    2、redo log 的写入机制
        事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。
        如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。
        redo log 可能存在的三种状态
        （1）存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；
        （2）写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；
        （3）持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多
        日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。

        为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：
        （1）设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;
        （2）设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；
        （3）设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

        InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。


        注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。
        也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。

        除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。
        （1）一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。
        （2）另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。

        两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。

        如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。

        每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。

        指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。

    3、组提交（group commit）机制
        日志逻辑序列号（log sequence number，LSN）
            LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。
            LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log
        redo log组提交的流程
            （1）trx1 是第一个到达的，会被选为这组的 leader；
            （2）等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；
            （3）trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；
            （4）这时候 trx2 和 trx3 就可以直接返回了。
            所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好
            在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。
        两阶段提交优化
            写 binlog 是分成两步的：
                （1）先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；
                （2）调用 fsync 持久化。
            优化后的二阶段提交：
                （1）redo log prepare:write
                （2）binlog:write
                （3）redo log prepare:fsync
                （4）binlog:fsync
                （5）redo log:commit:write
            在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。
            binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好
            提升 binlog 组提交的效果:
            （1）binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
            （2）binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。
            这两个条件是或的关系
            WAL 机制主要得益于两个方面：
            （1）redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；
            （2）组提交机制，可以大幅度降低磁盘的 IOPS 消耗。

            如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？
            （1）设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
            （2）将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
            （3）将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

24 | MySQL是怎么保证主备一致的？
    1、MySQL 主备的基本原理
        主A，备B切换为主B，备A
        状态1中，节点 B（也就是备库）设置成只读（readonly）模式
        （1）有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
        （2）防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
        （3）可以用 readonly 状态，来判断节点的角色。
        备库只读如果处理同步数据
            因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

        一个事务日志同步的完整过程是这样的：
        （1）在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
        （2）在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。
        （3）主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
        （4）备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
        （5）sql_thread 读取中转日志，解析出日志里的命令，并执行。
        多线程复制方案的引入，sql_thread 演化成为了多个线程
        日志分析：
           show binlog events in 'mysql_bin.000009';
            （1）statement
                由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。
            （2）row
                row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。Table_map event，用于说明接下来要操作的表是 test 库的表 t;Delete_rows event，用于定义删除的行为。
                Query-》Table_map-》Delete_rows-》Xid
                Table_map event，确定接下来操作的库和表
                Delete_rows event，用于定义删除的行为。
                执行命令分析执行细节：mysqlbinlog  -vv mysql_bin.000010 --start-position=2291;
                删除细节：
                    （1）server id 1，表示这个事务是在 server_id=1 的这个库上执行的。
                    （2）每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。
                    （3）Table_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。
                    （4）在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。
                    （5）binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。
                    （6）最后的 Xid event，用于表示事务被正确地提交了。你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。
                当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。

            （3）mixed
                产生的原因
                    （1）因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
                    （2）row 格式的缺点是，很占空间
                    所以mysql采用了要给这种的方案，就是mysql自己判断这个sql是否可能引起主备不一致，如果可能选择row，否则选择statement
                    比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。

            （4）小小结
                现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。
                delete，insert，update很最容易转成insert,delete,和update后前语句
                MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。
                SET TIMESTAMP 命令约定了接下来的 now()，同时也确保了，MySQL 就确保了主备数据的一致性。

                用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行
                mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;

            （5）误删数据的恢复（没整明白）
                reset master
                -- row
                SHOW BINARY LOGS;
                -- 查看binlog格式
                show variables like 'binlog_format';
                -- 查看日志记录
                show binlog events in 'mysql_bin.000003';
                -- 恢复删除记录
                mysqlbinlog --start-position=2291 --stop-position=2291 --database=test  "/usr/local/mysql/data/mysql_bin.000011" | mysql -uroot -p123456
                mysqlbinlog "/usr/local/mysql/data/mysql_bin.000011"  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P3306 -uroot -p123456
                set sql_log_bin=0;
                mysqlbinlog --base64-output=decode-rows -v --database=test --start-datetime="2023-12-09 09:48:00" --stop-datetime="2023-12-09 10:48:00" "/usr/local/mysql/data/mysql_bin.000011" > /tmp/binlog.sql
                mysqlbinlog --no-defaults  --base64-output=decode-rows --start-position=440 --stop-position=731 "/usr/local/mysql/data/mysql_bin.000002" > /tmp/binlog4.sql
                mysqlbinlog --no-defaults  --base64-output=decode-rows -v -v -d test  --start-position=157 --stop-position=440  /usr/local/mysql/data/mysql_bin.000001  >> /tmp/binlog1.sql
                select * from t;
                reset master
                show variables like '%gtid%'
            （6）循环复制问题
                实际生产上使用比较多的是双 M 结构，和M-S结构相比，其实区别只是多了一条线。即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。
                参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog。
                业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。
                如果点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。
                循环复制问题解决：
                （1）规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
                （2）一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；
                （3）每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。
                双M的日志执行流程
                （1）从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；
                （2）传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；
                （3）再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。

            （7）小结
                binlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。
            （8）问题
                MySQL 通过判断 server id 的方式，断掉死循环。但是，这个机制其实并不完备，在某些场景下，还是有可能出现死循环。
                （1）场景1：一种场景是，在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同
                （2）trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。
                    解决办法如下：
                        a：执行
                            stop slave；
                            CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B);
                            start slave;
                        b:执行
                            stop slave；
                            CHANGE MASTER TO IGNORE_SERVER_IDS=();
                        start slave;

25 | MySQL是怎么保证高可用的？
    正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。

    1、主备延迟
        时间点：
            （1）主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;
            （2）之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;
            （3）备库 B 执行完成这个事务，我们把这个时刻记为 T3。
        所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。
        备库执行show slave status，seconds_behind_master代表备库延迟了多少秒
        seconds_behind_master 的计算方法：
            （1）每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；
            （2）备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master

        备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间.
        主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。
        日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的

        所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢

    2、主备延迟的来源
        （1）备库所在机器的性能要比主库所在的机器性能差
            更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。
            更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。
            因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，
        （2）备库的压力大
            由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。
            结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。
            我们一般可以这么处理：
                （1）一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。
                （2）通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。
                一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。
                从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。
        （3）大事务
            主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。
                （1）不要一次性地用 delete 语句删除太多数据
                    在晚上执行这些大量数据的删除操作。
                （2）大表 DDL
                    计划内的 DDL，建议使用 gh-ost 方案
        （4）备库的并行复制能力
    （3）主备切换之"可靠性优先策略"
        切换步骤：
            （1）判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
            （2）把主库 A 改成只读状态，即把 readonly 设置为 true；
            （3）判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
            （4）把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
            （5）把业务请求切到备库 B。
        这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。
        这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。
        在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。
    （4）主备切换之"可用性优先策略"
        切换步骤：
            （1）把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
            （2）把业务请求切到备库 B。
            （3）判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
            （4）把主库 A 改成只读状态，即把 readonly 设置为 true；
            （5）判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
        这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。
            （1）使用 row 格式的 binlog 时，数据不一致的问题更容易被发现。
            （2）主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。
    （5）有没有哪种情况数据的可用性优先级更高呢？
        有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。
        同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。
    （6）按照可靠性优先的思路，异常切换会是什么效果？
        在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。
    （7）小结
        在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。
    （8）问题
        现在你看到你维护的一个备库，它的延迟监控的图像类似图 6，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？
        （1）一种是大事务（包括大表 DDL、一个事务操作很多行）；
        （2）还有一种情况比较隐蔽，就是备库起了一个长事务，主库对表 t 做了一个加字段操作，即使这个表很小，这个 DDL 在备库应用的时候也会被堵住，也不能看到这个现象。

26 | 备库为什么会延迟好几个小时？
    如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。
    主备的并行复制能力：
        （1）客户端写入主库
            主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的
        （2）备库上 sql_thread 执行中转日志（relay log）
            备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。
        在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。
        所有的多线程复制机制，都是要把图 1 中只有一个线程的 sql_thread，拆成多个线程
        coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。
        真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。
        根据我的经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。
        coordinator 在分发的时候，需要满足以下这两个基本要求：
            （1）不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。
            （2）一个事务不能被拆开，必须放到同一个 worker 中。
        （3）MySQL 5.6 版本的并行复制策略
            支持了并行复制，只是支持的粒度是按库并行。
            这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。
                （1）构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。
                （2）不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。
            缺点
                （1）如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；
                （2）或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。
        （4）MariaDB 的并行复制策略
            redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：
                （1）能够在同一组里提交的事务，一定不会修改同一行；
                （2）主库上可以并行执行的事务，备库上也一定是可以并行执行的。
            MariaDB 是这么做的：
                （1）在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；
                （2）commit_id 直接写到 binlog 里面；
                （3）传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
                （4）这一组全部执行完成后，coordinator 再去取下一批。
                MariaDB 的这个策略，目标是“模拟主库的并行模式”。
                但它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。
                在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。
        （5）MySQL 5.7 的并行复制策略
            由参数 slave-parallel-type 来控制并行复制策略：
            （1）配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；
            （2）配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。
            同时处于“执行状态”的所有事务，是不是可以并行？
                不能。因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。
                MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。
                其实不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。
            MySQL 5.7 并行复制策略的思想是：
            （1）同时处于 prepare 状态的事务，在备库执行时是可以并行的；
            （2）处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。
            使用下面的两个参数，更大的提高并行度
            （1）binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
            （2）binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。
            两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。
        （6）MySQL 5.7.22 的并行复制策略
            MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。
            通过参数binlog-transaction-dependency-tracking控制
                （1）COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
                （2）WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
                （3）WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

            当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。
            如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。
            很大的优势：
                （1）writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；
                （2）不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；
                （3）由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。
            当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。

        （7）小结
            单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。
            你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务
        （8）问题
            假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。这时候，你为了更快地让备库追上主库，要开并行复制。
            在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？
            答案：
                由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 COMMIT_ORDER 模式的话，从库也只能单线程执行。
                同样地，由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。
                所以，应该将 binlog-transaction-dependency-tracking 设置为 WRITESET。评论区留言点赞板：

27 | 主库出问题了，从库怎么办？
    A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。
    1、基于位点的主备切换
        （1）切换命令
            CHANGE MASTER TO
            MASTER_HOST=$host_name
            MASTER_PORT=$port
            MASTER_USER=$user_name
            MASTER_PASSWORD=$password
            MASTER_LOG_FILE=$master_log_name
            MASTER_LOG_POS=$master_log_pos
        （2）参数意思：
            （1）MASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。
            （2）最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。

        （3）切换时同步位点
            原来节点 B 是 A 的从库，本地记录的也是 A 的位点。但是相同的日志，A 的位点和 A’的位点是不同的。因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。
            考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。
            （1）取同步位点1
                （1）等待新主库 A’把中转日志（relay log）全部同步完成；
                （2）在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position；
                （3）取原主库 A 故障的时刻 T；
                （4）用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。
                    mysqlbinlog File --stop-datetime=T --start-datetime=T
                    end_log_pos 后面的值“123”，表示的就是 A’这个实例，在 T 时刻写入新的 binlog 的位置。然后，我们就可以把 123 这个值作为 $master_log_pos ，用在节点 B 的 change master 命令里。
                通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。
                    （1）做法1，主动跳过一个事务
                        set global sql_slave_skip_counter=1;
                        start slave;
                        因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。
                    （2）slave_skip_errors，直接设置跳过指定的错误
                        1062 错误是插入数据时唯一键冲突；
                        1032 错误是删除数据时找不到行。
                        我们可以把 slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。
                        这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。
                        等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空
            （2）GTID
                GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。
                格式：GTID=server_uuid:gno
                    server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；
                    gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。
                官方定义格式：
                    GTID=source_id:transaction_id
                source_id 就是 server_uuid；而后面的这个 transaction_id，我觉得容易造成误导，所以我改成了 gno。
                为什么说使用 transaction_id 容易造成误解呢？
                因为，在 MySQL 里面我们说 transaction_id 就是指事务 id，事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，
                而 gno 是在事务提交的时候才会分配。从效果上看，GTID 往往是连续的，因此我们用 gno 来表示更容易理解。

                GTID 模式的启动也很简单，我们只需要在启动一个 MySQL 实例的时候，加上参数 gtid_mode=on 和 enforce_gtid_consistency=on 就可以了。

                在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值。
                （1）如果 gtid_next=automatic，代表使用默认值。
                    这时，MySQL 就会把 server_uuid:gno 分配给这个事务。
                        a. 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’;
                        b. 把这个 GTID 加入本实例的 GTID 集合。
                （2）如果 gtid_next 是一个指定的 GTID 的值
                    比如通过 set gtid_next='current_gtid’指定为 current_gtid，那么就有两种可能：
                        a. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；
                        b. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。
                        一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。
                    每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”。

                set gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';
                begin;
                commit;
                set gtid_next=automatic;
                start slave;
                前三条语句的作用，是通过提交一个空事务，把这个 GTID 加到实例 X 的 GTID 集合中
                start slave 命令让同步线程执行起来的时候，虽然实例 X 上还是会继续执行实例 Y 传过来的事务，但是由于“aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”已经存在于实例 X 的 GTID 集合中了，所以实例 X 就会直接跳过这个事务，也就不会再出现主键冲突的错误。
                start slave 命令之前还有一句 set gtid_next=automatic。这句话的作用是“恢复 GTID 的默认分配行为”，也就是说如果之后有新的事务再执行，就还是按照原来的分配方式，继续分配 gno=3。

        （4）基于 GTID 的主备切换
            CHANGE MASTER TO
            MASTER_HOST=$host_name
            MASTER_PORT=$port
            MASTER_USER=$user_name
            MASTER_PASSWORD=$password
            master_auto_position=1
            master_auto_position=1 就表示这个主备关系使用的是 GTID 协议。
            在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：
            （1）实例 B 指定主库 A’，基于主备协议建立连接。
            （2）实例 B 把 set_b 发给主库 A’。
            （3）实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。
                a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；
                b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；
            （4）之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。
        （5）GTID 和在线 DDL
            在双 M 结构下，备库执行的 DDL 语句也会传给主库，为了避免传回后对主库造成影响，要通过 set sql_log_bin=off 关掉 binlog。
            这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样：
            （1）在实例 X 上执行 stop slave。
            （2）在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。
            （3）执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。
            （4）到实例 X 上执行以下语句序列：
                set GTID_NEXT="server_uuid_of_Y:gno";
                begin;
                commit;
                set gtid_next=automatic;
                start slave;
        （6）小结：
            可以看到，在 GTID 模式下，一主多从切换就非常方便了。因此，如果你使用的 MySQL 版本支持 GTID 的话，我都建议你尽量使用 GTID 模式来做一主多从的切换。
        （7）问题：
            GTID 模式下设置主从关系的时候，从库执行 start slave 命令后，主库发现需要的 binlog 已经被删除掉了，导致主备创建不成功。
            （1）如果业务允许主从不一致的情况
                那么可以在主库上先执行 show global variables like ‘gtid_purged’，
                得到主库已经删除的 GTID 集合，假设是 gtid_purged1；
                然后先在从库上执行 reset master，再执行 set global gtid_purged =‘gtid_purged1’；
                最后执行 start slave，就会从主库现存的 binlog 开始同步。
                binlog 缺失的那一部分，数据在从库上就可能会有丢失，造成主从不一致。
            （2）如果需要主从数据一致的话，最好还是通过重新搭建从库来做。
            （3）如果有其他的从库保留有全量的 binlog 的话，可以把新的从库先接到这个保留了全量 binlog 的从库，追上日志以后，如果有需要，再接回主库。
            （4）如果 binlog 有备份的情况，可以先在从库上应用缺失的 binlog，然后再执行 start slave。


28 | 读写分离有哪些坑？
    读写分离的主要目标就是分摊主库的压力，一般有两种架构
        （1）客户端直连方案
            客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询。
            因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。
            由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。
            一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，
        （2）带 proxy 的架构
           中间代理层 proxy，客户端只连接 proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。
           对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。
           但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。
        趋势是往带 proxy 的架构方向发展的
    1、过期读问题
        （1）强制走主库方案
            强制走主库方案其实就是，将查询请求做分类。
                对于必须要拿到最新结果的请求，强制将其发到主库上。
                对于可以读到旧数据的请求，才将其发到从库上
            有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。
        （2）sleep方案
            类似于执行一条 select sleep(1)
            不建议
        （3）判断主备无延迟方案
            （1）第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。
            （2）对比位点确保主备无延迟：
                如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。
            （3）对比 GTID 集合确保主备无延迟：
                Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。
                Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；
                Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。
                如果这两个集合相同，也表示备库接收到的日志都已经同步完成。
                对比位点和对比 GTID 这两种方法，都要比判断 seconds_behind_master 是否为 0 更准确。
                判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。
            trx1 和 trx2 已经传到从库，并且已经执行完成了；
            trx3 在主库执行完成，并且已经回复给客户端，但是还没有传到从库中。
            如果这时候你在从库 B 上执行查询请求，按照我们上面的逻辑，从库认为已经没有同步延迟，但还是查不到 trx3 的。严格地说，就是出现了过期读。
            （4）配合 semi-sync
                要解决这个问题，就要引入半同步复制，也就是 semi-sync replication。semi-sync 做了这样的设计：
                （1）事务提交的时候，主库把 binlog 发给从库；
                （2）从库收到 binlog 以后，发回给主库一个 ack，表示收到了；
                （3）主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。
                如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。
                semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。
                这时，在从库上执行查询请求，就有两种情况：
                （1）如果查询是落在这个响应了 ack 的从库上，是能够确保读到最新数据；
                （2）但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。
                小结一下，semi-sync 配合判断主备无延迟的方案，存在两个问题：
                （1）一主多从的时候，在某些从库执行查询请求会存在过期读的现象；
                （2）在持续延迟的情况下，可能出现过度等待的问题。
            （5）等主库位点方案
                select master_pos_wait(file, pos[, timeout]);
                    （1）它是在从库执行的；
                    （2）参数 file 和 pos 指的是主库上的文件名和位置；
                    （3）timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。
                正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。
                其他的一些结果：
                    （1）如果执行期间，备库同步线程发生异常，则返回 NULL；
                    （2）如果等待超过 N 秒，就返回 -1；
                    （3）如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。
                要保证能够查到正确的数据，我们可以使用这个逻辑：
                    （1）trx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position；
                    （2）选定一个从库执行查询语句；
                    （3）在从库上执行 select master_pos_wait(File, Position, 1)；
                    （4）如果返回值是 >=0 的正整数，则在这个从库执行查询语句；
                    （5）否则，到主库执行查询语句。
            （6）GTID 方案
                 select wait_for_executed_gtid_set(gtid_set, 1);
                 这条命令的逻辑是：
                    等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；
                    超时返回 1。
                MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。
                等 GTID 的执行流程就变成了：
                （1）trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；
                （2）选定一个从库执行查询语句；
                （3）在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；
                （4）如果返回值是 0，则在这个从库执行查询语句；
                （5）否则，到主库执行查询语句。
                跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。
                你只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可。

        2、小结
            先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期读；然后，对于不能接受过期读的语句，再使用等 GTID 或等位点的方案。
            在实际应用中，可能会有别的不需要等待就可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中取权衡。
        3、问题
            假设你的系统采用了我们文中介绍的最后一个方案，也就是等 GTID 的方案，现在你要对主库的一张大表做 DDL，可能会出现什么情况呢？为了避免这种情况，你会怎么做呢？
            答案：
                假设，这条语句在主库上要执行 10 分钟，提交后传到备库就要 10 分钟（典型的大事务）。
                那么，在主库 DDL 之后再提交的事务的 GTID，去备库查的时候，就会等 10 分钟才出现。
                这样，这个读写分离机制在这 10 分钟之内都会超时，然后走主库。
                这种预期内的操作，应该在业务低峰期的时候，确保主库能够支持所有业务查询，然后把读请求都切到主库，再在主库上做 DDL。
                等备库延迟追上以后，再把读请求切回备库。
                通过这个思考题，我主要想让关注的是，大事务对等位点方案的影响。
                当然了，使用 gh-ost 方案来解决这个问题也是不错的选择。


29 | 如何判断一个数据库是不是出问题了？
    在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上
    主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起的。

    1、select 1判断
        innodb_thread_concurrency，并发线程上限数
        并发连接和并发查询，并不是同一个概念。
        你在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。
        而“当前正在执行”的语句，才是我们所说的并发查询。
        并发连接数达到几千个影响并不大，就是多占一些内存而已。
        我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。
        这也是为什么我们需要设置 innodb_thread_concurrency 参数的原因。
        在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。MySQL 这样设计是非常有意义的。因为，进入锁等待的线程已经不吃 CPU 了；更重要的是，必须这么设计，才能避免整个系统锁死。
        我们说 InnoDB 在设计时，遇到进程进入锁等待的情况时，将并发线程的计数减 1 的设计，是合理而且是必要的。
        执行的语句超过了设置的 innodb_thread_concurrency 的值，这时候系统其实已经不行了，但是通过 select 1 来检测系统，会认为系统还是正常的。
    2、查表判断
        为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：
            mysql> select * from mysql.health_check;
        更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。
    3、更新判断
        既然要更新，就要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：
        mysql> update mysql.health_check set t_modified=now();
        为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。
        mysql> CREATE TABLE `health_check` (
          `id` int(11) NOT NULL,
          `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
          PRIMARY KEY (`id`)
        ) ENGINE=InnoDB;

        /* 检测命令 */
        insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();

        IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO 资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。

        update 命令没有超时，于是就得到了“系统正常”的结论。
        根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。

    4、内部统计
        MySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。
    5、小结
        select 1 这样的方法是不是已经被淘汰了呢，但实际上使用非常广泛的 MHA（Master High Availability），默认使用的就是这个方法。
        每个改进的方案，都会增加额外损耗，并不能用“对错”做直接判断，需要你根据业务实际情况去做权衡。
        我个人比较倾向的方案，是优先考虑 update 系统表，然后再配合增加检测 performance_schema 的信息。
    6、问题
        业务系统一般也有高可用的需求，在你开发和维护过的服务中，你是怎么判断服务有没有出问题的呢？
        答案：
            （1）关于服务状态和服务质量的监控。其中，服务状态的监控，一般都可以用外部系统来实现；而服务的质量的监控，就要通过接口的响应时间来统计。
            （2）提到服务中使用了 healthCheck 来检测，其实跟我们文中提到的 select 1 的模式类似。
            （3）按照监控的对象，将监控分成了基础监控、服务监控和业务监控，并分享了每种监控需要关注的对象。

30 | 答疑文章（二）：用动态的观点看加锁
    加锁规则。这个规则中，包含了两个“原则”、两个“优化”和一个“bug”：
        原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
        原则 2：查找过程中访问到的对象才会加锁。
        优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
        优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
        一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。
    1、不等号条件里的等值查询
        begin;
        select * from t where id>9 and id<12 order by id desc for update;
        （1）首先这个查询语句的语义是 order by id desc，要拿到满足条件的所有行，优化器必须先找到“第一个 id<12 的值”。
        （2）这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 id=12 的这个值，只是最终没找到，但找到了 (10,15) 这个间隙。
        （3）然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 id=5 这一行，所以会加一个 next-key lock (0,5]。
        在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法。
    2、等值查询的过程
        begin;
        select id from t where c in(5,20,10) lock in share mode;
            先锁 c=5，然后 c=10，最后是 c=20
        begin;
        select id from t where c in(5,20,10) order by c desc for update;
            由于语句里面是 order by c desc， 这三个记录锁的加锁顺序，是先锁 c=20，然后 c=10，最后是 c=5
            这些锁是“在执行过程中一个一个加的”，而不是一次性加上去的。
        这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，就可能出现死锁。
    3、怎么看死锁？
        show engine innodb status 命令得到的部分输出。这个命令会输出很多信息，有一节 LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息。

        我们可以得到两个结论：
            由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；
            在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。
    4、怎么看锁等待？
        所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。
    5、小结：
        分析加锁范围时，一定要配合语句执行逻辑来进行。
        每个想认真了解 MySQL 原理的同学，应该都要能够做到：
            通过 explain 的结果，就能够脑补出一个 SQL 语句的执行流程。达到这样的程度，才算是对索引组织表、索引、锁的概念有了比较清晰的认识。
        show engine innodb status输出结果中的事务信息和死锁信息
        所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。
    6、问题：
        一个空表有间隙吗？这个间隙是由谁定义的？你怎么验证这个结论呢？？
        答案：
            一个空表就只有一个间隙。这个查询语句加锁的范围就是 next-key lock (-∞, supremum]。

31 | 误删数据后除了跑路，还能怎么办？
    传统的高可用架构是不能预防误删数据的，因为主库的一个 drop table 命令，会通过 binlog 传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。
    1、误删行
        使用flashback来恢复
            Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。
            需要确保 binlog_format=row 和 binlog_row_image=FULL。
            具体恢复数据时，对单个事务做如下处理：
            （1）对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可；
            （2）同理，对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event；
            （3）而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。
        多个事务应该reverse
        恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。
            一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。

        我们不止要说误删数据的事后处理办法，更重要是要做到事前预防
            （1）把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。
            （2）代码上线前，必须经过 SQL 审计。

    2、误删表
        要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog。
        （1）取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；
        （2）用备份恢复出一个临时库；
        （3）从日志备份里面，取出凌晨 0 点之后的日志；
        （4）把这些日志，除了误删除数据的语句外，全部应用到临时库。
        几点说明:
        （1）–database 参数，用来指定误删表所在的库
        （2）应用日志的时候，需要跳过误操作的那个binglog
            无gtid:
                先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；
            gtid:
                set gtid_next=gtid1;begin;commit;
                先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。
        使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个：
            （1）如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是 mysqlbinlog 工具并不能指定只解析一个表的日志；
            （2）用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。我们在第 26 篇文章中介绍的那些并行复制的方法，在这里都用不上。
        一种加速的方法是，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样：
            在 start slave 之前，先通过执行change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；
            这样做也可以用上并行复制技术，来加速整个数据恢复过程。
        不论是把 mysqlbinlog 工具解析出的 binlog 文件应用到临时库，还是把临时库接到备库上，这两个方案的共同点是：误删库或者表后，恢复数据的思路主要就是通过备份，再加上应用 binlog 的方式。
        这两个方案都要求备份系统定期备份全量日志，而且需要确保 binlog 在被从本地删除之前已经做了备份。
        我建议你不论使用上述哪种方式，都要把这个数据恢复功能做成自动化工具，并且经常拿出来演练。为什么这么说呢？
        （1）虽然“发生这种事，大家都不想的”，但是万一出现了误删事件，能够快速恢复数据，将损失降到最小，也应该不用跑路了。
        （2）而如果临时再手忙脚乱地手动操作，最后又误操作了，对业务造成了二次伤害，那就说不过去了

    （3）延迟复制备库
        如果有非常核心的业务，不允许太长的恢复时间，我们可以考虑搭建延迟复制的备库
        一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。
        延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
        这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。
    （4）预防误删库 / 表的方法
        （1）账号分离。
            只给业务开发同学 DML 权限，而不给 truncate/drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持。
            即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。
        （2）制定操作规范。这样做的目的，是避免写错要删除的表名。
            （1）在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。
            （2）改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。
    （5）rm 删除数据
        一般没事
    （6）小结：
        预防远比处理的意义来得大。
    （7）回忆下你亲身经历过的误删数据事件吧，你用了什么方法来恢复数据呢？你在这个过程中得到的经验又是什么呢？

32 | 为什么还有kill不掉的语句？（没看懂，用处不大）
    1、两种kill
        kill query id:表示终止这个线程中正在执行的语句
        kill(collection)id:断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的
    2、使用了 kill 命令，却没能断开这个连接。再执行 show processlist 命令，看到这条语句的 Command 列显示的是 Killed?
        kill query/connection 命令是有效的。比如，执行一个查询的过程中，发现执行时间太久，要放弃继续查询，这时我们就可以用 kill query 命令，终止这条查询语句
        语句处于锁等待的时候，直接使用 kill 命令也是有效的
    3、收到 kill 以后，线程做什么？
        kill 并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。
        实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：
            （1）把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；
            （2）给 session B 的执行线程发一个信号。
        为什么要发信号呢？如果只是把 session B 的线程状态设置 THD::KILL_QUERY，线程 B 并不知道这个状态变化，还是会继续等待。
        发一个信号的目的，就是让 session B 退出等待，来处理这个 THD::KILL_QUERY 状态。
        隐含了这么三层意思：
            （1）一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD::KILL_QUERY，才开始进入语句终止逻辑；
            （2）如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；
            （3）语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。

        set global innodb_thread_concurrency=2，不够用；
        客户端虽然断开了连接，但实际上服务端上这条语句还在执行过程中。
        在实现上，等行锁时，使用的是 pthread_cond_timedwait 函数，这个等待状态可以被唤醒。
        每 10 毫秒判断一下是否可以进入 InnoDB 执行，如果不行，就调用 nanosleep 函数进入 sleep 状态。
        虽然 12 号线程的状态已经被设置成了 KILL_QUERY，但是在这个等待进入 InnoDB 的循环过程中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。


        这个例子是 kill 无效的第一类情况，即：线程没有执行到判断线程状态的逻辑。跟这种情况相同的，还有由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态。
        另一类情况是，终止逻辑耗时较长。这时候，从 show processlist 结果上看也是 Command=Killed，需要等到终止逻辑完成，语句才算真正完成。这类情况，比较常见的场景有以下几种：
        （1）超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。
        （2）大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。
        （3）DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。
    4、另外两个关于客户端的误解
        第一个误解是：如果库里面的表特别多，连接就会很慢
            （1）执行 show databases；
            （2）切到 db1 库，执行 show tables；
            （3）把这两个命令的结果用于构建一个本地的哈希表。
            我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。

    小结：
        因为发送 kill 命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被 kill 的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。

        如果你发现一个线程处于 Killed 状态，你可以做的事情就是，通过影响系统环境，让这个 Killed 状态尽快结束。比如，
        （1）如果是第一个例子里 InnoDB 并发度的问题，你就可以临时调大 innodb_thread_concurrency 的值，或者停掉别的线程，让出位子给这个线程执行。
        （2）而如果是回滚逻辑由于受到 IO 资源限制执行得比较慢，就通过减少系统压力让它加速。
        做完这些操作后，其实你已经没有办法再对它做什么了，只能等待流程自己完成。

33 | 我查这么多数据，会不会把数据库内存打爆？
    1、全表扫描对 server 层的影响
        InnoDB 的数据是保存在主键索引上的，所以全表扫描实际上是直接扫描表 t 的主键索引。取数据和发数据的流程是这样的：
        （1）获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
        （2）重复获取行，直到 net_buffer 写满，调用网络接口发出去。
        （3）如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
        （4）如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。
        从这个流程中，你可以看到：
        （1）一个查询在发送过程中，占用的 MySQL 内部的内存最大就是 net_buffer_length 这么大，并不会达到 200G；
        （2）socket send buffer 也不可能达到 200G（默认定义 /proc/sys/net/core/wmem_default），如果 socket send buffer 被写满，就会暂停读数据的流程。
        MySQL 是“边读边发的”，就是我故意让客户端不去读 socket receive buffer 中的内容，如果你看到 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。

        对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，我都建议你使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。

        如果要快速减少处于这个状态的线程的话，将 net_buffer_length 参数设置为一个更大的值是一个可选方案。
        一个查询语句的状态变化是这样的（注意：这里，我略去了其他无关的状态）：
        （1）MySQL 查询语句进入执行阶段后，首先把状态设置成“Sending data”；
        （2）然后，发送执行结果的列相关的信息（meta data) 给客户端；
        （3）再继续执行语句的流程；
        （4）执行完成后，把状态设置成空字符串。
        “Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。

        仅当一个线程处于“等待客户端接收结果”的状态，才会显示"Sending to client"；而如果显示成“Sending data”，它的意思只是“正在执行”。
    （2）全表扫描对 InnoDB 的影响
        我介绍 WAL 机制的时候，和你分析了 InnoDB 内存的一个作用，是保存更新的结果，再配合 redo log，就避免了随机写盘。
        内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。
        内存数据页的结果是最新的，直接读内存页就可以了。你看，这时候查询根本不需要读磁盘，直接从内存拿结果，速度是很快的。所以说，Buffer Pool 还有加速查询的作用。
        内存命中率。show engine innodb status 结果中，查看一个系统当前的 BP 命中率。一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。
        执行 show engine innodb status ，可以看到“Buffer pool hit rate”字样。

        InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%。

        InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。
        但是不能直接使用这个算法，按照这个算法扫描的话，就会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。
        也就是说 Buffer Pool 里面主要放的是这个历史数据表的数据。Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。

        实际上，InnoDB 对 LRU 算法做了改进。
            在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。
            改进后的 LRU 算法执行流程变成了下面这样。
            （1）图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。
            （2）之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，
            （3）但是新插入的数据页 Px，是放在 LRU_old 处。
            （4）处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：
                若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；
                如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。
            1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。

        就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描 200G 的历史数据表为例，我们看看改进后的 LRU 算法的操作逻辑：
        （1）扫描过程中，需要新插入的数据页，都被放到 old 区域 ;
        （2）一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；
        （3）再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。
        这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。
    3、小结
        由于 MySQL 采用的是边算边发的逻辑，因此对于数据量很大的查询结果来说，不会在 server 端保存完整的结果集。
        所以，如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是不会把内存打爆。
        而对于 InnoDB 引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。
        并且，由于 InnoDB 对 LRU 算法做了改进，冷数据的全表扫描，对 Buffer Pool 的影响也能做到可控。

        全表扫描还是比较耗费 IO 资源的，所以业务高峰期还是不能直接在线上主库执行全表扫描的。

34 | 到底可不可以使用join？
    1、Index Nested-Loop Join（NLJ）
        这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。
        select * from t1 straight_join t2 on (t1.a=t2.a);
        执行流程：
            （1）从表 t1 中读入一行数据 R；
            （2）从数据行 R 中，取出 a 字段到表 t2 里去查找；
            （3）取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；
            （4）重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。
        在这个流程里：
            （1）对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；
            （2）而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；
            （3）所以，整个执行流程，总扫描行数是 200。
        在这个 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。
        每次搜索一棵树近似复杂度是以 2 为底的 M 的对数，记为 log2M，所以在被驱动表上查一行的时间复杂度是 2*log2M。
        假设驱动表的行数是 N，执行过程就要扫描驱动表 N 行，然后对于每一行，到被驱动表上匹配一次。
        因此整个执行过程，近似复杂度是 N + N*2*log2M。
        小小结：
            使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；
            如果使用 join 语句的话，需要让小表做驱动表。

    2、Simple Nested-Loop Join
        select * from t1 straight_join t2 on (t1.a=t2.b);
        由于表 t2 的字段 b 上没有索引，因此再用图 2 的执行流程时，每次到 t2 去匹配的时候，就要做一次全表扫描。
        这样算来，这个 SQL 请求就要扫描表 t2 多达 100 次，总共扫描 100*1000=10 万行。
        MySQL 也没有使用这个 Simple Nested-Loop Join 算法，而是使用了另一个叫作“Block Nested-Loop Join”的算法，简称 BNL。
    3、Block Nested-Loop Join(BNJ)
        被驱动表上没有可用的索引，算法的流程是这样的：
        （1）把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；
        （2）扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。
        可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。
        由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。
        假设小表的行数是 N，大表的行数是 M，那么在这个算法里：
            两个表都做一次全表扫描，所以总的扫描行数是 M+N；
            内存中的判断次数是 M*N。
        调换这两个算式中的 M 和 N 没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。

        join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。
        如果放不下表 t1 的所有数据话，策略很简单，就是分段放。我把 join_buffer_size 改成 1200，
        （1）扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；
        （2）扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；
        （3）清空 join_buffer；继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。

        这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”。
        这时候由于表 t1 被分成了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88+12)*1000=10 万次
        这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ*N，显然λ的取值范围是 (0,1)。
        所以，在这个算法的执行过程中：
            扫描行数是 N+λ*N*M；
            内存判断 N*M 次。
        所以结论是，应该让小表当驱动表。
        join_buffer_size 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。

        第一个问题：能不能使用 join 语句？
            （1）如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
            （2）如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。
                尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。
        第二个问题是：如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？
            （1）如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；
            （2）如果是 Block Nested-Loop Join 算法：
                在 join_buffer_size 足够大的时候，是一样的；
                在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。
            所以，这个问题的结论就是，总是应该使用小表做驱动表。
    3、什么叫作“小表”。
        在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。
    4、小结
        通过对 Index Nested-Loop Join 和 Block Nested-Loop Join 两个算法执行过程的分析，我们也得到了文章开头两个问题的答案：
        （1）如果可以使用被驱动表的索引，join 语句还是有其优势的；
        （2）不能使用被驱动表的索引，只能使用 Block Nested-Loop Join 算法，这样的语句就尽量不要使用；
        （3）在使用 join 的时候，应该让小表做驱动表。
    5、问题
        如果被驱动表是一个大表，并且是一个冷数据表，除了查询过程中可能会导致 IO 压力大以外，你觉得对这个 MySQL 服务还有什么更严重的影响吗？
        答案：
            会降低缓存命中率

35 | join语句怎么优化？
    1、Multi-Range Read 优化（MRR）
        这个优化的主要目的是尽量使用顺序读盘。
        回表是指，InnoDB 在普通索引 a 上查到主键 id 的值后，再根据一个个主键 id 的值到主键索引上去查整行数据的过程。
        因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。
        就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：
        （1）根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
        （2）将 read_rnd_buffer 中的 id 进行递增排序；
        （3）排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。
        read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。
        如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。
        之后继续找索引 a 的下个记录，并继续循环。
        通过set optimizer_switch="mrr_cost_based=off"，设置使用mrr
        Extra 字段多了 Using MRR，表示的是用上了 MRR 优化。
        而且，由于我们在 read_rnd_buffer 中按照 id 做了排序，所以最后得到的结果集也是按照主键 id 递增顺序的，也就是与图 1 结果集中行的顺序相反。
        MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。
    2、Batched Key Access（BKA）
        NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。
        那怎么才能一次性地多传些值给表 t2 呢？方法就是，从表 t1 里一次性地多拿些行出来，一起传给表 t2。
        既然如此，我们就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是 join_buffer。
        BKA算法启用：set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
        前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于 MRR。
    3、BNL算法的性能问题
        由于 InnoDB 对 Bufffer Pool 的 LRU 算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在 old 区域。
        如果 1 秒之后这个数据页不再被访问了，就不会被移动到 LRU 链表头部，这样对 Buffer Pool 的命中率影响就不大。
        问题1：
            如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。
            这种情况对应的，是冷表的数据量小于整个 Buffer Pool 的 3/8，能够完全放入 old 区域的情况。
        问题2：
            一个正常访问的数据页，要进入 young 区域，需要隔 1 秒后再次被访问到。
            但是，由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。
            这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰。
            业务正常访问的数据页，没有机会进入 young 区域
        大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。
        但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。

        可以考虑增大 join_buffer_size 的值，减少对被驱动表的扫描次数,BNL 算法对系统的影响主要包括三个方面：
        （1）可能会多次扫描被驱动表，占用磁盘 IO 资源；
        （2）判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；
        （3）可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。
        给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。
    4、BNL 转 BKA
        我们可以直接在被驱动表上建索引，这时就可以直接转成 BKA 算法了。
        有时候你确实会碰到一些不适合在被驱动表上建索引的情况。
        xxxxxxxxxxxxxxxxxx
        xxxxxxxxxxxxxxxxxx
        这时候，我们可以考虑使用临时表。使用临时表的大致思路是：
       （1）把表 t2 中满足条件的数据放在临时表 tmp_t 中；
       （2）为了让 join 使用 BKA 算法，给临时表 tmp_t 的字段 b 加上索引；
       （3）让表 t1 和 tmp_t 做 join 操作。

        执行 insert 语句构造 temp_t 表并插入数据的过程中，对表 t2 做了全表扫描，这里扫描行数是 100 万。
        之后的 join 语句，扫描表 t1，这里的扫描行数是 1000；join 比较过程中，做了 1000 次带索引的查询。
        相比于优化前的 join 语句需要做 10 亿次条件判断来说，这个优化效果还是很明显的。

        不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能。
    5、扩展 -hash join
        也正是 MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join。并且，MySQL 官方的 roadmap，也是迟迟没有把这个优化排上议程。
        我们可以自己实现在业务端。实现流程大致如下：
        （1）select * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。
        （2）select * from t2 where b>=1 and b<=2000;
        （3）获取表 t2 中满足条件的 2000 行数据。把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。理论上，这个过程会比临时表方案的执行速度还要快一些。

    6、小结
        （1）BKA 优化是 MySQL 已经内置支持的，建议你默认使用；
        （2）BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引；
        （3）基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；
        （4）MySQL 目前的版本还不支持 hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。
    7、问题（没明白）
        select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c>=X and t2.c>=Y and t3.c>=Z;
        现在为了得到最快的执行速度，如果让你来设计表 t1、t2、t3 上的索引，来支持这个 join 语句，你会加哪些索引呢？
        答案：
            如果改写成 straight_join，要怎么指定连接顺序，以及怎么给三个表创建索引。
            第一原则是要尽量使用 BKA 算法。需要注意的是，使用 BKA 算法的时候，并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询的。
            具体实现是：
            在 t1.c>=X、t2.c>=Y、t3.c>=Z 这三个条件里，选择一个经过过滤以后，数据最少的那个表，作为第一个驱动表。
            此时，可能会出现如下两种情况。
                第一种情况，如果选出来是表 t1 或者 t3，那剩下的部分就固定了。
                    如果驱动表是 t1，则连接顺序是 t1->t2->t3，要在被驱动表字段创建上索引，也就是 t2.a 和 t3.b 上创建索引；
                    如果驱动表是 t3，则连接顺序是 t3->t2->t1，需要在 t2.b 和 t1.a 上创建索引。
                    同时，我们还需要在第一个驱动表的字段 c 上创建索引。
                第二种情况是，如果选出来的第一个驱动表是表 t2 的话，
                    则需要评估另外两个条件的过滤效果。
                总之，整体的思路就是，尽量让每一次参与 join 的驱动表的数据集，越小越好，因为这样我们的驱动表就会越小。

36 | 为什么临时表可以重名？
    内存表：
        内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。
        这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。
    临时表：
        可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。
        当然，临时表也可以使用 Memory 引擎。
    1、临时表的特性
        （1）建表语法是 create temporary table …。
        （2）一个临时表只能被创建它的 session 访问，对其他线程不可见。
            所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。
        （3）临时表可以与普通表同名。
        （4）session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。
        （5）show tables 命令不显示临时表。

        临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。
        临时表就特别适合我们文章开头的 join 优化这种场景：
        （1）不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。
        （2）不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。
            而临时表由于会自动回收，所以不需要这个额外的操作。
    2、临时表的应用
        由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。
        这种分库分表系统都有一个中间层 proxy。不过，也有一些方案会让客户端直接连接数据库，也就是没有 proxy 这一层。
        在这个架构中，分区 key 的选择是以“减少跨库和跨表查询”为依据的。如果大部分的语句都会包含 f 的等值条件，那么就要用 f 做分区键。

        由于查询条件里面没有用到分区字段 f，只能到所有的分区中去查找满足条件的所有行，然后统一做 order by 的操作。
        （1）第一种思路是，在 proxy 层的进程代码中实现排序
            需要的开发工作量比较大。
            对 proxy 端的压力比较大，尤其是很容易出现内存不够用和 CPU 瓶颈的问题。
        （2）另一种思路
            把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。
            （1）在汇总库上创建一个临时表 temp_ht，表里包含三个字段 v、k、t_modified；
            （2）在各个分库上执行select v,k,t_modified from ht_x where k >= M order by t_modified desc limit 100;
            （3）把分库执行的结果插入到 temp_ht 表中；
            （4）执行
            我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表 temp_ht 放到 32 个分库中的某一个上。
    3、为什么临时表可以重名？
        MySQL 要给这个 InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据。
        这个 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程 id}_{线程 id}_ 序列号”。
        你可以使用 select @@tmpdir 命令，来显示实例的临时文件目录。
        表中数据的存放方式：
            （1）在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件；
            （2）而从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建 ibd 文件了。
        MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。
            （1）一个普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了。
            （2）而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。
        每个线程都维护了自己的临时表链表。
        这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；
        在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作。

    4、临时表和主备复制
        如果当前的 binlog_format=row，那么跟临时表有关的语句，就不会记录到 binlog 里。
        也就是说，只在 binlog_format=statment/mixed 的时候，binlog 中才会记录临时表的操作。

        创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。
        主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。
        所以，这时候我们就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行。
        设置 binlog_format=row，drop temp table不会同步到从库；否则会同步到从库
        drop table 命令记录 binlog 的时候，就必须对语句做改写。

        主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？
        MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。
        这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key：
        （1）session A 的临时表 t1，在备库的 table_def_key 就是：库名 +t1+“M 的 serverid”+“session A 的 thread_id”;
        （2）session B 的临时表 t1，在备库的 table_def_key 就是 ：库名 +t1+“M 的 serverid”+“session B 的 thread_id”。
        由于 table_def_key 不同，所以这两个表在备库的应用线程里面是不会冲突的。
    5、小结
        临时表一般用于处理比较复杂的计算逻辑。
        由于临时表是每个线程自己可见的，所以不需要考虑多个线程执行同一个处理逻辑时，临时表的重名问题。
        在线程退出的时候，临时表也能自动删除，省去了收尾和异常处理的工作。
        在 binlog_format='row’的时候，临时表的操作不记录到 binlog 中，也省去了不少麻烦，这也可以成为你选择 binlog_format 时的一个考虑因素。
        需要注意的是，我们上面说到的这种临时表，是用户自己创建的 ，也可以称为用户临时表。
    6、问题
        我们可以使用 alter table 语法修改临时表的表名，而不能使用 rename 语法。你知道这是什么原因吗？
            在实现上，执行 rename table 语句的时候，要求按照“库名 / 表名.frm”的规则去磁盘找文件，
            但是临时表在磁盘上的 frm 文件是放在 tmpdir 目录下的，并且文件名的规则是“#sql{进程 id}_{线程 id}_ 序列号.frm”，因此会报“找不到文件名”的错误。

37 | 什么时候会使用内部临时表？
    sort buffer、内存临时表和 join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助 SQL 语句的执行的。
    其中，我们在排序的时候用到了 sort buffer，在使用 join 语句的时候用到了 join buffer。
    1、union 执行流程
        union的意思是取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。
        这个语句的执行流程是这样的：
        （1）创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段。
        （2）执行第一个子查询，得到 1000 这个值，并存入临时表中。
        （3）执行第二个子查询：拿到第一行 id=1000，试图插入临时表中。但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；
        （4）取到第二行 id=999，插入临时表成功。从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是 1000 和 999。
        如果把上面这个语句中的 union 改成 union all 的话，就没有了“去重”的语义。
        这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。
    2、group by 执行流程
        select id%10 as m, count(*) as c from t1 group by m;
        在 Extra 字段里面，我们可以看到三个信息：
        （1）Using index，表示这个语句使用了覆盖索引，选择了索引 a，不需要回表；
        （2）Using temporary，表示使用了临时表；
        （3）Using filesort，表示需要排序。
        这个语句的执行流程是这样的：
        （1）创建内存临时表，表里有两个字段 m 和 c，主键是 m；
        （2）扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；
                如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);
                如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；
        （3）遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。
        如果你的需求并不需要对结果进行排序，那你可以在 SQL 语句末尾增加 order by null
        内存可以放得下，因此全程只使用了内存临时表。但是，内存临时表的大小是有限制的，参数 tmp_table_size 就是控制这个内存大小的，默认是 16M。
        这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是 InnoDB。
    3、group by 优化方法 -- 索引
        不论是使用内存临时表还是磁盘临时表，group by 逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的。
        如果可以确保输入的数据是有序的，那么计算 group by 的时候，就只需要从左到右，顺序扫描，依次累加。也就是下面这个过程：
            当碰到第一个 1 的时候，已经知道累积了 X 个 0，结果集里的第一行就是 (0,X);
            当碰到第一个 2 的时候，已经知道累积了 Y 个 1，结果集里的第二行就是 (1,Y);
        在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新。
        alter table t1 add column z int generated always as(id % 100), add index(z);
        改写为：
        select z, count(*) as c from t1 group by z;
    4、group by 优化方法 -- 索引
        接走磁盘临时表
        在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。
        MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。
        所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。
        select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
        执行流程就是这样的：
        （1）初始化 sort_buffer，确定放入一个整型字段，记为 m；
        （2）扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中；
        （3）扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）；
        （4）排序完成后，就得到了一个有序数组。
        从 Extra 字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。

    5、MySQL 什么时候会使用内部临时表？
    （1）如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；
    （2）join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；
    （3）如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。
    6、小结
    （1）如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；
    （2）尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；
    （3）如果 group by 需要统计的数据量不大，尽量只使用内存临时表；
    （4）也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；
    （5）如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。

38 | 都说InnoDB好，那还要不要使用Memory引擎？
    InnoDB 表的数据就放在主键索引树上，主键索引是 B+ 树。
        主键索引上的值是有序存储的。在执行 select * 的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0 就出现在第一行。
    Memory 引擎的数据和索引是分开的。
        内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。
        当我执行 select * 的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0 就是最后一个被读到，并放入结果集的数据。
    可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：
    （1）InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。
    （2）而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。
    这两个引擎的一些典型不同
    （1）InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
    （2）当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
    （3）数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
    （4）InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
    （5）InnoDB 支持变长数据类型，不同记录的长度可能不同；
        内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

    1、hash 索引和 B-Tree 索引
        内存表也是支持 B-Tree 索引的。在 id 列上创建一个 B-Tree 索引，SQL 语句可以这么写：
            alter table t1 add index a_btree_index using btree (id);
        一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。
        为什么我不建议你在生产环境上使用内存表。这里的原因主要包括两个方面：
        （1）锁粒度问题；
        （2）数据持久化问题。
    2、内存表的锁
        内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。
        表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。
    3、数据持久性问题
        数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。
        M-S 架构下，使用内存表存在的问题：
        （1）业务正常访问主库；
        （2）备库硬件升级，备库重启，内存表 t1 内容被清空；
        （3）备库重启后，客户端发送一条 update 语句，修改表 t1 的数据行，这时备库应用线程就会报错“找不到要更新的行”。
        这样就会导致主备同步停止
        由于 MySQL 知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，MySQL 在实现上做了这样一件事儿：在数据库重启之后，往 binlog 里面写入一行 DELETE FROM t1。
        在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。
        但是内存表执行速度快呀。这个问题，其实你可以这么分析：
        （1）如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB 支持行锁，并发度比内存表好；
        （2）能放到内存表的数据量都不大。
            如果你考虑的是读的性能，一个读 QPS 很高并且数据量不大的表，即使是使用 InnoDB，数据也是都会缓存在 InnoDB Buffer Pool 里的。
            因此，使用 InnoDB 表的读性能也不会差。
        我建议你把普通内存表都用 InnoDB 表来代替。但是，有一个场景却是例外的。
        就是，用户临时表。在数据量可控，不会耗费过多内存的情况下，你可以考虑使用内存表。
        内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：
        （1）临时表不会被其他线程访问，没有并发性的问题；
        （2）临时表重启后也是需要删除的，清空数据这个问题不存在；
        （3）备库的临时表也不会影响主库的用户线程。
        其实这里使用内存临时表的效果更好，原因有三个：
        （1）相比于 InnoDB 表，使用内存表不需要写磁盘，往表 temp_t 的写数据的速度更快；
        （2）索引 b 使用 hash 索引，查找的速度比 B-Tree 索引快；
        （3）临时表数据只有 2000 行，占用的内存有限。
        可以看到，不论是导入数据的时间，还是执行 join 的时间，使用内存临时表的速度都比使用 InnoDB 临时表要更快一些。
    4、小结
        由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；
        如果主库跟这个备库是双 M 架构，还可能导致主库的内存表数据被删掉。
        因此，在生产上，我不建议你使用普通内存表。
        如果你是 DBA，可以在建表的审核系统中增加这类规则，要求业务改用 InnoDB 表。
        我们在文中也分析了，其实 InnoDB 表性能还不错，而且数据安全也有保障。
        而内存表由于不支持行锁，更新语句会阻塞查询，性能也未必就如想象中那么好。
        基于内存表的特性，我们还分析了它的一个适用场景，就是内存临时表。内存表支持 hash 索引，这个特性利用起来，对复杂查询的加速效果还是很不错的。
    5、问题
        假设你刚刚接手的一个数据库上，真的发现了一个内存表。备库重启之后肯定是会导致备库的内存表数据被清空，进而导致主备同步停止。
        这时，最好的做法是将它修改成 InnoDB 引擎表。假设当时的业务场景暂时不允许你修改引擎，你可以加上什么自动化逻辑，来避免主备同步停止呢？
        答案：
            那么就把备库的内存表引擎先都改成 InnoDB。对于每个内存表，执行
                set sql_log_bin=off;
                alter table tbl_name engine=innodb;
            这样就能避免备库重启的时候，数据丢失的问题。
            由于主库重启后，会往 binlog 里面写“delete from tbl_name”，这个命令传到备库，备库的同名的表数据也会被清空。

39 | 自增主键为什么不是连续的？
    自增主键，由于自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。
    1、自增值保存在哪儿？
        虽然show create table，会显示自增值。但，表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。
        不同的引擎对于自增值的保存策略不同：
        （1）MyISAM 引擎的自增值保存在数据文件中。
        （2）InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，具体情况是：
            （1）在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。
                每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。
                举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。
                这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。
                但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。
                也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。
            （2）在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。
    2、自增值修改机制
        （1）如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；
        （2）如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。
            某次要插入的值是 X，当前的自增值是 Y。
                （1）如果 X<Y，那么这个表的自增值不变；
                （2）如果 X≥Y，就需要把当前自增值修改为新的自增
        新的自增值生成算法是：从 auto_increment_offset 开始，以 auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。
        auto_increment_offset 和 auto_increment_increment 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。
        备注：在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。
    3、自增值的修改时机
        （1）唯一键冲突是导致自增主键 id 不连续的第一种原因。
        （2）事务回滚也会产生类似的现象，这就是第二种原因。
    4、自增值为什么不能回退。
        解决自增值连续，有两个方案：
            （1）每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在。
            （2）把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。
        这两个方法都会导致性能问题。
        InnoDB 放弃了这个设计，语句执行失败也不回退自增 id。也正是因为这样，所以才只保证了自增 id 是递增的，但不保证是连续的。
    5、自增锁的优化
        自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。
        MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值是 1。
        （1）这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；
        （2）这个参数的值被设置为 1 时：
            普通 insert 语句，自增锁在申请之后就马上释放；
            类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
        （3）这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。

            在生产上，尤其是有 insert … select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：
            innodb_autoinc_lock_mode=2 ，并且 binlog_format=row. 这样做，既能提升并发性，又不会出现数据一致性问题。
            在普通的 insert 语句里面包含多个 value 值的情况下，即使 innodb_autoinc_lock_mode 设置为 1，也不会等语句执行完成才释放锁。
            因为这类语句在申请自增 id 的时候，是可以精确计算出需要多少个 id 的，然后一次性申请，申请完成后锁就可以释放了。
            MySQL 有一个批量申请自增 id 的策略：
                语句执行过程中，第一次申请自增 id，会分配 1 个；
                1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；
                2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；
                依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍
    6、小结
        在 MyISAM 引擎里面，自增值是被写在数据文件上的。
        而在 InnoDB 中，自增值是被记录在内存的。
        MySQL 直到 8.0 版本，才给 InnoDB 表的自增值加上了持久化的能力，确保重启前后一个表的自增值不变。
        MySQL 5.1.22 版本开始引入的参数 innodb_autoinc_lock_mode，控制了自增值申请时的锁范围。从并发性能的角度考虑，我建议你将其设置为 2，同时将 binlog_format 设置为 row。
    7、问题
        在最后一个例子中，执行 insert into t2(c,d) select c,d from t;
        这个语句的时候，如果隔离级别是可重复读（repeatable read），binlog_format=statement。这个语句会对表 t 的所有记录和间隙加锁。
        答案：

40 | insert语句的锁为什么这么多？
    1、insert … select 语句
        insert into t2(c,d) select c,d from t;需要对表 t 的所有行和间隙加锁呢？
        在binlog_format=statement的条件下，为了防止主备不一致。
    2、insert 循环写入
        执行 insert … select 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。
        insert into t2(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
        这个语句的加锁范围，就是表 t 索引 c 上的 (3,4]和 (4,supremum]这两个 next-key lock，以及主键索引上 id=4 这一行。

        insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
        执行流程：
            （1）创建临时表，表里有两个字段 c 和 d。
            （2）按照索引 c 扫描表 t，依次取 c=4、3、2、1，然后回表，读到 c 和 d 的值写入临时表。
                这时，Rows_examined=4。
            （3）由于语义里面有 limit 1，所以只取了临时表的第一行，再插入到表 t 中。这时，Rows_examined 的值加 1，变成了 5。
            这个语句会导致在表 t 上做全表扫描，并且会给索引 c 上的所有间隙都加上共享的 next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。
            至于这个语句的执行为什么需要临时表？
                原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。
            优化办法：
                create temporary table temp_t(c int,d int) engine=memory;
                insert into temp_t  (select c+1, d from t force index(c) order by c desc limit 1);
                insert into t select * from temp_t;
                drop table temp_t;
    3、insert 唯一键冲突
        唯一键冲突导致的死锁场景
        （1）在 T1 时刻，启动 session A，并执行 insert 语句，此时在索引 c 的 c=5 上加了记录锁。注意，这个索引是唯一索引，因此退化为记录锁（如果你的印象模糊了，可以回顾下第 21 篇文章介绍的加锁规则）。
        （2）在 T2 时刻，session B 要执行相同的 insert 语句，发现了唯一键冲突，加上读锁；同样地，session C 也在索引 c 上，c=5 这一个记录上，加了读锁。
        （3）T3 时刻，session A 回滚。这时候，session B 和 session C 都试图继续执行插入操作，都要加上写锁。两个 session 都要等待对方的行锁，所以就出现了死锁。
    4、小结
        insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁。
        如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。
        insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。

41 | 怎么最快地复制一张表？
    为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表
    1、mysqldump 方法
        mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
        （1）–single-transaction 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用 START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法；
        （2）–add-locks 设置为 0，表示在输出的文件结果里，不增加" LOCK TABLES t WRITE;" ；
        （3）–no-create-info 的意思是，不需要导出表结构；
        （4）–set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息；
        （5）–result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的。
        可以看到，一条 INSERT 语句里面会包含多个 value 对，这是为了后续用这个文件来写入数据的时候，执行速度可以更快。
        你可以通过下面这条命令，将这些 INSERT 语句放到 db2 库里去执行。
        mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
        source 并不是一条 SQL 语句，而是一个客户端命令。
        mysql 客户端执行这个命令的流程是这样的：
            打开文件，默认以分号为结尾读取一条条的 SQL 语句；
            将 SQL 语句发送到服务端执行。
    2、导出 CSV 文件
        select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
        需要注意的是：
        （1）这条语句会将结果保存在服务端。
        （2）into outfile 指定了文件的生成位置（/server_tmp/）
        （3）这条命令不会帮你覆盖文件
        导入数据：
        load data 命令将数据导入到目标表 db2.t 中。
        load data infile '/server_tmp/t.csv' into table db2.t;
    3、物理拷贝方法
        在 MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。
        （1）执行 create table r like t，创建一个相同表结构的空表；
        （2）执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；
        （3）执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；
        （4）在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；
        （5）执行 unlock tables，这时候 t.cfg 文件会被删除；
        （6）执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。
        注意点：
            （1）在第 3 步执行完 flsuh table 命令之后，db1.t 整个表处于只读状态，直到执行 unlock tables 命令后才释放读锁；
            （2）在执行 import tablespace 的时候，为了让文件里的表空间 id 和数据字典中的一致，会修改 r.ibd 的表空间 id。
                而这个表空间 id 存在于每一个数据页中。
                因此，如果是一个很大的文件（比如 TB 级别），每个数据页都需要修改，所以你会看到这个 import 语句的执行是需要一些时间的。
                当然，如果是相比于逻辑导入的方法，import 语句的耗时是非常短的。
    4、小结
        （1）物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。
            如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：
            （1）必须是全表拷贝，不能只拷贝部分数据；
            （2）需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；
            （3）由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。
        （2）用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。
            这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。
        （3）用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。
            但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。
    5、问题
        我们前面介绍 binlog_format=statement 的时候，binlog 记录的 load data 命令是带 local 的。既然这条命令是发送到备库去执行的，那么备库执行的时候也是本地执行，为什么需要这个 local 呢？如果写到 binlog 中的命令不带 local，又会出现什么问题呢？
        为了确保备库应用 binlog 正常。因为备库可能配置了 secure_file_priv=null，所以如果不用 local 的话，可能会导入失败，造成主备同步延迟。
        另一种应用场景是使用 mysqlbinlog 工具解析 binlog 文件，并应用到目标库的情况。
        你可以使用下面这条命令 ：mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd把日志直接解析出来发给目标库执行。

42 | grant之后要跟着flush privileges吗？
    create user 'ua'@'%' identified by 'pa';
    在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户
    这条命令做了两个动作：
    （1）磁盘上，往 mysql.user 表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是 N；
    （2）内存里，往数组 acl_users 里插入一个 acl_user 对象，这个对象的 access 字段值为 0。
    1、全局权限
        grant all privileges on *.* to 'ua'@'%' with grant option;
        （1）磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为‘Y’；
        （2）内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。
        在这个 grant 命令执行完成后，如果有新的客户端使用用户名 ua 登录成功，MySQL 会为新连接维护一个线程对象，
        然后从 acl_users 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。
        之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。
        可以知道：
        （1）grant 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。
        （2）对于一个已经存在的连接，它的全局权限不受 grant 命令的影响。
        一般在生产环境上要合理控制用户权限的范围。
        收回权限：
            revoke all privileges on *.* from 'ua'@'%';
            （1）磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为“N”；
            （2）内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 的值修改为 0。
    2、db 权限
        如果要让用户 ua 拥有库 db1 的所有权限，可以执行下面这条命令：
        grant all privileges on db1.* to 'ua'@'%' with grant option;
        基于库的权限记录保存在 mysql.db 表中，在内存里则保存在数组 acl_dbs 中。这条 grant 命令做了如下两个动作：
        （1）磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”；
        （2）内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。
        每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 acl_dbs 数组，根据 user、host 和 db 找到匹配的对象，然后根据对象的权限位来判断。
        grant 修改 db 权限的时候，是同时对磁盘和内存生效的。

        grant 操作对于已经存在的连接的影响，在全局权限和基于 db 的权限效果是不同的。

        xxxxxxxxxxx
        xxxxxxxxxxx
        （不用看）
    3、表权限和列权限
        MySQL 支持更细粒度的表权限和列权限。
        其中，表权限定义存放在表 mysql.tables_priv 中，列权限定义存放在表 mysql.columns_priv 中。
        这两类权限，组合起来存放在内存的 hash 结构 column_priv_hash 中。
        赋权命令如下：
            create table db1.t1(id int, a int);
            grant all privileges on db1.t1 to 'ua'@'%' with grant option;
            GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO 'ua'@'%' with grant option;
        跟 db 权限类似，这两个权限每次 grant 的时候都会修改数据表，也会同步修改内存中的 hash 结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接。

        flush privileges 命令会清空 acl_users 数组，然后从 mysql.user 表中读取数据重新加载，重新构造一个 acl_users 数组。
        也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。
        同样地，对于 db 权限、表权限和列权限，MySQL 也做了这样的处理。

        如果内存的权限数据和磁盘数据表相同的话，不需要执行 flush privileges。而如果我们都是用 grant/revoke 语句来执行的话，内存和数据表本来就是保持同步更新的。
        因此，正常情况下，grant 命令之后，没有必要跟着执行 flush privileges 命令。
    4、flush privileges 使用场景
        当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态。
        不规范的场景：
            （1）不一致往往是由不规范的操作导致的，比如直接用 DML 语句操作系统权限表
    5、小结
        grant 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用 grant 和 revoke 语句，是不需要随后加上 flush privileges 语句的。
        flush privileges 语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。
            而这种不一致往往是由于直接用 DML 语句操作系统权限表导致的，所以我们尽量不要使用这类语句。

43 | 要不要使用分区表？
    CREATE TABLE `t` (
      `ftime` datetime NOT NULL,
      `c` int(11) DEFAULT NULL,
      KEY (`ftime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=latin1
    PARTITION BY RANGE (YEAR(ftime))
    (PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
     PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
     PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
    PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);
    insert into t values('2017-4-1',1),('2018-4-1',1);
    这个表包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件。
        也就是说：对于引擎层来说，这是 4 个表；
        对于 Server 层来说，这是 1 个表。
    1、分区表的引擎层行为
        由于分区表的规则，session A 的 select 语句其实只操作了分区 p_2018，因此加锁范围就是图 4 中深绿色的部分。
        所以，session B 要写入一行 ftime 是 2018-2-1 的时候是可以成功的，而要写入 2017-12-1 这个记录，就要等 session A 的间隙锁。

        再来一个 MyISAM 分区表的例子
            alter table t engine=myisam，把表 t 改成 MyISAM 表
            这正是因为 MyISAM 的表锁是在引擎层实现的，session A 加的表锁，其实是锁在分区 p_2018 上。因此，只会堵住在这个分区上执行的查询，落到其他分区的查询是不受影响的。

        分区表看来还不错嘛，为什么不让用呢？
            我们使用分区表的一个重要原因就是单表过大。那么，如果不使用分区表的话，我们就是要使用手动分表的方式。
        手动分表和分区表有什么区别。
            （1）手工分表的逻辑，也是找到需要更新的所有分表，然后依次执行更新。在性能上，这和分区表并没有实质的差别。
            （2）分区表和手工分表，一个是由 server 层来决定使用哪个分区，一个是由应用层代码来决定使用哪个分表。
                因此，从引擎层看，这两种方式也是没有差别的。
            （3）主要是在 server 层上。
                从 server 层看，我们就不得不提到分区表一个被广为诟病的问题：打开表的行为。
    2、分区策略
        每当第一次访问一个分区表的时候，MySQL 需要把所有的分区都访问一遍。
            由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错
            从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略。
            虽然 session B 只需要操作 p_2017 这个分区，但是由于 session A 持有整个表 t 的 MDL 锁，就导致了 session B 的 alter 语句被堵住。
            分区表，在做 DDL 的时候，影响会更大
        小小结：
            （1）MySQL 在第一次打开分区表的时候，需要访问所有的分区；
            （2）在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；
            （3）在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。
    3、分区表的应用场景
        分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据
        按照时间分区的分区表，就可以直接通过 alter table t drop partition ... 这个语法删掉分区，从而删掉过期的历史数据。
        这个 alter table t drop partition ... 操作是直接删除分区文件，效果跟 drop 普通表类似。与使用 delete 语句删除数据相比，优势是速度快、对系统影响小。
    4、小结
        分区表跟用户分表比起来，有两个绕不开的问题：
            一个是第一次访问的时候需要访问所有分区，
            另一个是共用 MDL 锁。
        分组表注意事项：
            （1）分区并不是越细越好。
            （2）分区也不要提前预留太多，在使用之前预先创建即可。
        当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对 DBA 也更直观，自然是更好的。

    5、问题
        MySQL 要求分区表中的主键必须包含分区字段。如果要在表 t 的基础上做修改，你会怎么定义这个表的主键呢？为什么这么定义呢？
        这时候就有两种可选：一种是 (ftime, id)，另一种是 (id, ftime)。
        如果从利用率上来看，应该使用 (ftime, id) 这种模式。
        因为用 ftime 做分区 key，说明大多数语句都是包含 ftime 的，使用这种模式，可以利用前缀索引的规则，减少一个索引。

44 | 答疑文章（三）：说一说这些好问题
    1、join 的写法
        使用 left join 时，左边的表不一定是驱动表。

45 | 自增id用完怎么办？
    1、表定义自增值 id
        表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。
    2、InnoDB 系统自增 row_id
        如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 row_id。
        写入表的 row_id 是从 0 开始到 248-1。达到上限后，下一个值就是 0，然后继续循环
    3、Xid
        MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。
        global_query_id 是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。
        MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。
        MySQL 重启不会导致同一个 binlog 里面出现两个相同的 Xid，但是如果 global_query_id 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。
        global_query_id 定义的长度是 8 个字节，这个自增值的上限是 264-1。要出现这种情况，必须是下面这样的过程：
        （1）执行一个事务，假设 Xid 是 A；
        （2）接下来执行 264次查询语句，让 global_query_id 回到 A；
        （3）再启动一个事务，这个事务的 Xid 也是 A。
    4、Innodb trx_id
        Xid 和 InnoDB 的 trx_id 是两个容易混淆的概念。Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。
        InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。
        InnoDB 数据可见性的核心思想是：
            每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。
        对于正在执行的事务，你可以从 information_schema.innodb_trx 表中看到事务的 trx_id

        只读事务不分配 trx_id，有什么好处呢？
            （1）一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。
            （2）另一个好处是，可以减少 trx_id 的申请次数
    5、thread_id
        线程 id 才是 MySQL 中最常见的一种自增 id。平时我们在查各种现场的时候，show processlist 里面的第一列，就是 thread_id。
        thread_id 的逻辑很好理解：
            系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。
    6、小结
        （1）表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
        （2）row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。
        （3）Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
        （4）InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，
            所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
        （5）thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。
        












